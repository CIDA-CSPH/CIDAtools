<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Computing on the CSPH Biostats Cluster • CIDAtools</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Computing on the CSPH Biostats Cluster">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">CIDAtools</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/alpine.html">Alpine HPC</a></li>
    <li><a class="dropdown-item" href="../articles/CIDA_BIOS_Cluster_Interactive_IDEs.html">RStudio/JupyterLab on the CSPH Biostats Cluster</a></li>
    <li><a class="dropdown-item" href="../articles/CIDA_BIOS_Cluster.html">Computing on the CSPH Biostats Cluster</a></li>
    <li><a class="dropdown-item" href="../articles/CIDA_computing_resources.html">CIDA Computing Resources</a></li>
    <li><a class="dropdown-item" href="../articles/coding_guidelines.html">CIDA-coding-guidelines</a></li>
    <li><a class="dropdown-item" href="../articles/cron-jobs.html">Cron Jobs</a></li>
    <li><a class="dropdown-item" href="../articles/data_storage.html">CIDA-data-storage-guidelines</a></li>
    <li><a class="dropdown-item" href="../articles/git.html">Tracking code in Git/GitHub</a></li>
    <li><a class="dropdown-item" href="../articles/sas-macros.html">CIDA SAS Macros</a></li>
    <li><a class="dropdown-item" href="../articles/tabling_packages.html">Tabling Packages</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Computing on the CSPH Biostats Cluster</h1>
                        <h4 data-toc-skip class="author">Research Tools
Committee</h4>
            
            <h4 data-toc-skip class="date">Last Updated: 2025-06-03</h4>
      

      <div class="d-none name"><code>CIDA_BIOS_Cluster.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="definitions">Definitions<a class="anchor" aria-label="anchor" href="#definitions"></a>
</h2>
<ul>
<li>
<a name="def_hpc"></a><strong>HPC</strong> - High-performance
Computing</li>
<li>
<a name="def_node"></a><strong>Node</strong> - A single computer in
the cluster’s network. Most HPC clusters have a <em>head node</em> and
one or more <em>compute nodes</em>
</li>
<li>
<a name="def_headnode"></a><strong>Head Node</strong> - A node
within the cluster which serves as the user’s access/login point to the
cluster. Depending on cluster configuration, the head node may also be
responsible for scheduling and distributing jobs to the compute
nodes.</li>
<li>
<a name="def_compnode"></a><strong>Compute Node</strong> - A node
within the cluster which is designated for running user-submitting jobs.
Compute nodes usually offer large amounts of computational resources
(CPU cores, RAM, etc).</li>
<li>
<a name="def_clust"></a><strong>Cluster</strong> - A group of
networked computers, usually running cluster-management software to
coordinate resource sharing among multiple users.</li>
<li>
<a name="def_job"></a><strong>Job</strong> - A computational task
executed on the cluster. A submitted job will be scheduled and executed
on one of the compute nodes.</li>
</ul>
</div>
<div class="section level2">
<h2 id="introduction-to-hpc-high-performance-computing">Introduction to HPC (High-Performance Computing)<a class="anchor" aria-label="anchor" href="#introduction-to-hpc-high-performance-computing"></a>
</h2>
<p>An HPC cluster is a group of networked high-performance computers
(<em>nodes</em>).</p>
<p>A typical cluster will have multiple <em>compute nodes</em> which can
perform heavy computation, as well as a <em>head node</em> which serves
as the user’s access point to the cluster, and may also be responsible
for scheduling jobs among the <em>compute nodes</em>. The <em>compute
nodes</em> in an cluster typically have compute resources (CPU Cores,
RAM, Disk Space) which far exceed those of a typical laptop or desktop
computer.</p>
<p>Because HPC clusters are intended to serve a group of people (i.e. A
biostatistics department) rather than a single user, HPC clusters use
the concept of <a href="#def_job">jobs</a> to allow for multiple users
to effectively share the cluster’s resources.</p>
<p>When a user is ready to run something (an analysis, processing
pipeline, etc) on the cluster, they will submit a new <em>job</em> to
the cluster. The cluster will then schedule and run the job as soon as
compute resources are available.</p>
<p><img src="figures/CIDA_BIOS_Cluster/cluster_basic_diagram.png" width="80%" style="display: block; margin: auto;"></p>
<p>The example figure above shows an example cluster with three users.
Each user connects to the Head Node to submit their jobs.</p>
<p>User 1 has submitted two jobs, which are both running on Compute Node
1. User 2 has submitted a single job, which is also running on Compute
Node 2. User 3 has submitted a job which requires a larger amount of
compute resources (CPU cores, RAM, etc). This job runs on Compute Node 2
to provide the user with the resources they requested.</p>
<p>HPC clusters are useful for:</p>
<ol style="list-style-type: decimal">
<li>Performing analyses which take a long time to run (i.e. A
large-scale analysis which takes hours to complete)</li>
<li>Performing analyses which are too resource-intensive (require too
much RAM, Disk Space, etc) to run on a typical computer.</li>
</ol>
</div>
<div class="section level2">
<h2 id="csph-biostats-hpc-cluster">CSPH Biostats HPC Cluster<a class="anchor" aria-label="anchor" href="#csph-biostats-hpc-cluster"></a>
</h2>
<p>The CSPH Biostats cluster consists of four nodes. The
<code>csphbiostats.ucdenver.pvt</code> node serves as both a head node
and one of the compute nodes (i.e. Submitted jobs may also run on this
node), and the <code>cidalappc[1-3].ucdenver.pvt</code> nodes serve as
compute nodes.</p>
<p><img src="figures/CIDA_BIOS_Cluster/Biostats_HPC_diagram.png" width="100%" style="display: block; margin: auto;"></p>
<p>The CIDA/Biostats server uses the <a href="https://slurm.schedmd.com" class="external-link">SLURM</a> system to manage job
scheduling and resource management on the cluster.</p>
</div>
<div class="section level2">
<h2 id="accessing-the-csph-biostats-cluster">Accessing the CSPH Biostats Cluster<a class="anchor" aria-label="anchor" href="#accessing-the-csph-biostats-cluster"></a>
</h2>
<p>To access the CSPH Biostats cluster, first submit a support ticket on
the <a href="https://medschool.cuanschutz.edu/informationservices" class="external-link">SOM
IS web page</a> requesting:</p>
<ol style="list-style-type: decimal">
<li>Access to the ‘CSPH/CIDA Biostats Cluster’.</li>
<li>(optional) A directory under <code>/biostats_share</code>
(i.e. <code>/biostats_share/&lt;your_username&gt;</code>).</li>
</ol>
<p>Once approved, an account will be created for you on the server.</p>
<p>To log in to the CSPH Biostats Cluster, you can use SSH from the
command line or an SSH client of your choice.</p>
<p><img src="figures/CIDA_BIOS_Cluster/biostats_hpc_ssh.png" width="80%" style="display: block; margin: auto;"></p>
<p>If you are connecting from the command line (like the above example),
run:</p>
<pre><code>ssh &lt;your_username&gt;@csphbiostats.ucdenver.pvt</code></pre>
<p>where <code>&lt;your_username&gt;</code> is your CU system username
(i.e Your username for UCDAccess, Outlook, etc)</p>
<p>On login, you will be prompted for a password which will be your CU
system password (i.e. Your password for UCDAccess, Outlook, etc).</p>
<p>Once you’ve successfully logged in, you should see a prompt like the
final line in the screenshot, showing that you are logged in to
<code>csphbiostats.ucdenver.pvt</code>.</p>
<p>To make future logins more convenient, you could configure an SSH
config profile and RSA key pair, which will enable password-less
login.</p>
</div>
<div class="section level2">
<h2 id="submitting-a-job-on-the-csph-biostats-cluster">Submitting a Job on the CSPH Biostats Cluster<a class="anchor" aria-label="anchor" href="#submitting-a-job-on-the-csph-biostats-cluster"></a>
</h2>
<p>In the sections below, I will describe a few different ways of
submitting a job on the cluster, along with their potential use
cases.</p>
<div class="section level3">
<h3 id="using-sbatch">Using <code>sbatch</code><a class="anchor" aria-label="anchor" href="#using-sbatch"></a>
</h3>
<p>The most common way of submitting a job on the cluster is to use the
<code>sbatch</code> command.</p>
<p>To submit a job using <code>sbatch</code>, you should first create a
batch script which will list the commands to be executed as part of your
job.</p>
<p>The below example shows a simple batch script
<code>my_batch.sh</code> which executes a single R script.</p>
<pre><code>#!/bin/bash
#SBATCH --job-name=my_batch
#SBATCH --output=my_batch.log
#SBATCH --error=my_batch.err

Rscript my_analysis.R</code></pre>
<p>The first line:</p>
<p><code>#!/bin/bash</code></p>
<p>is required, and is used to determine how your script will be
executed. In this case, the script will be executed using
<code>bash</code>.</p>
<p>The next few lines will be parsed by SLURM to set parameters/options
for your batch job.</p>
<pre><code><span><span class="co">#SBATCH --job-name=my_batch</span></span>
<span><span class="co">#SBATCH --output=my_batch.log</span></span>
<span><span class="co">#SBATCH --error=my_batch.err</span></span></code></pre>
<p>In order:</p>
<ol style="list-style-type: decimal">
<li>
<code>--job-name</code> - Sets a name for your job.</li>
<li>
<code>--output</code> - Sets the output log file for your job. Any
log messsages or outputs from your script will be sent to this
file.</li>
<li>
<code>--error</code> - Sets the error log file for your job. Any log
or error messages produced by your script will be sent to this
file.</li>
</ol>
<p>Any comment line containing <code>#SBATCH</code> before the first
command in your script will be parsed by SLURM.</p>
<p>Although <code>#SBATCH</code> lines are not required, I recommend at
least providing the <code>--output</code> and <code>--error</code>
options, since otherwise your output and error streams will both be
directed to the default file <code>slurm-&lt;job_id&gt;.out</code></p>
<p>We can submit this job by running:</p>
<pre><code>sbatch my_batch.sh</code></pre>
<p><img src="figures/CIDA_BIOS_Cluster/cluster_sbatch.png" width="80%" style="display: block; margin: auto;"></p>
<p>When we execute the <code>sbatch</code> command, SLURM will assign
the job an ID and schedule the job to execute. In this case, our job is
assigned ID <code>6179</code> (first arrow in the figure).</p>
<p>By using the <code>squeue</code> command, we can obtain the status of
all jobs currently scheduled across the cluster (including those
submitted by other users).</p>
<p>Using the assigned job ID, we can use the <code>JOBID</code> column
to identify our job in the queue (second arrow in the figure).</p>
<p>The <code>squeue</code> also provides some useful information about
our job:</p>
<ul>
<li>The <code>ST</code> column tells us that our job is in the running
(<code>R</code>) state.</li>
<li>The <code>TIME</code> column tells us that our job has been running
for 9 seconds.</li>
<li>The <code>NODELIST(REASON)</code> column tells us that our job is
executing on the <code>csphbiostats.ucdenver.pvt</code> node.</li>
</ul>
<div class="section level4">
<h4 id="when-to-use-sbatch">When to use <code>sbatch</code><a class="anchor" aria-label="anchor" href="#when-to-use-sbatch"></a>
</h4>
<p>Using <code>sbatch</code> is most beneficial for long-running scripts
or analyses. After the job has been submitted using <code>sbatch</code>,
your job will execute on the cluster until completion. You can continue
to work on the cluster (submitting other jobs, etc) or log out without
affecting any of your running jobs.</p>
<p>You can monitor the progress of your job using by checking your log
(<code>--output</code>) and error (<code>--error</code>) output files to
see any outputs/messages printed by your script.</p>
<p>Additionally, you can use the <code>squeue</code> command to obtain
other information about your job, including the current state
(<code>ST</code>), the elapsed runtime (<code>TIME</code>), and location
of your job (<code>NODELIST</code>).</p>
</div>
</div>
<div class="section level3">
<h3 id="using-srun">Using <code>srun</code><a class="anchor" aria-label="anchor" href="#using-srun"></a>
</h3>
<p>Submitting a job using SLURM’s <code>srun</code> command will
schedule and run the job as soon as possible. When the job begins to
run, you will see the output of the job in your terminal as it
executes.</p>
<p>Similar to running a script locally on the command line
(i.e. <code>./my_script.sh</code>), you will not be able to execute
other commands in your terminal window until the submitted job is
complete.</p>
<p>An example below shows execution of a simple shell script using
<code>srun</code>.</p>
<p>The command:</p>
<pre><code>srun --exclude=csphbiostats.ucdenver.pvt ./my_script.sh</code></pre>
<p>will schedule a new job to run the script
<code>./my_script.sh</code>.</p>
<p>The <code>--exclude</code> flag tells SLURM to schedule the job on
any node except the node(s) listed. In this case, we exclude the
<code>csphbiostats.ucdenver.pvt</code> node to ensure our job runs on
one of the <code>cidalappc[1-3].ucdenver.pvt</code> nodes (and the first
line of the script output shows our job ran on
<code>cidalappc01</code>).</p>
<p><img src="figures/CIDA_BIOS_Cluster/cluster_srun.png" width="80%" style="display: block; margin: auto;"></p>
<div class="section level4">
<h4 id="interactive-jobs">Interactive Jobs<a class="anchor" aria-label="anchor" href="#interactive-jobs"></a>
</h4>
<p><code>srun</code> is also useful for running <em>interactive</em>
jobs. An interactive job opens a terminal session on a compute node,
allowing you to run commands and script interactively.</p>
<p>Interactive jobs are useful for running quick commands or scripts, or
anytime you’d like to directly monitor the output of your
script/command.</p>
<p>The command:</p>
<pre><code><span><span class="va">srun</span> <span class="op">-</span><span class="op">-</span><span class="va">pty</span> <span class="op">-</span><span class="op">-</span><span class="va">exclude</span><span class="op">=</span><span class="va">csphbiostats.ucdenver.pvt</span> <span class="op">/</span><span class="va">bin</span><span class="op">/</span><span class="va">bash</span> <span class="op">-</span><span class="va">i</span></span></code></pre>
<p>will schedule a new interactive job on a compute node.</p>
<p>This command is similar to the previous <code>srun</code> command we
used but has a few key differences:</p>
<ol style="list-style-type: decimal">
<li>The addition of the <code>--pty</code> flag tells SLURM that this is
an interactive job.</li>
<li>The command <code>/bin/bash -i</code> will execute an interactive
shell on the compute node.</li>
</ol>
<p>After submitting the job, we see the prompt string has changed
from:</p>
<p><code>[hillandr@csphbiostats job_example]</code></p>
<p>to</p>
<p><code>[hillandr@cidalappc01 job_example]</code>.</p>
<p>This indicates that we are now running an interactive job on the
compute node <code>cidalappc01</code>.</p>
<p>At this point, we can execute any commands or scripts normally.</p>
<p>To end the interactive job, type <code>exit</code>.</p>
<p><img src="figures/CIDA_BIOS_Cluster/interactive_job.png" width="80%" style="display: block; margin: auto;"></p>
</div>
<div class="section level4">
<h4 id="when-to-use-srun">When to use <code>srun</code><a class="anchor" aria-label="anchor" href="#when-to-use-srun"></a>
</h4>
<p><code>srun</code> is useful for running interactive jobs with
fast-running commands/scripts, or for debugging issues with a larger
script you will eventually submit using <code>sbatch</code>.</p>
<p>I don’t recommend using <code>srun</code> for long-running jobs, as
if you disconnect from the cluster while the <code>srun</code> command
is still executing, the job may be cancelled.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="uploading-data-to-the-csph-biostats-cluster">Uploading Data to the CSPH Biostats Cluster<a class="anchor" aria-label="anchor" href="#uploading-data-to-the-csph-biostats-cluster"></a>
</h2>
<p>To upload and download data from the cluster, it is most convenient
to use SFTP. There are multiple ways to use SFTP, including through the
command line using the <code>sftp</code> command (Mac/Unix-like systems
only)</p>
<p>On Mac, the <a href="https://cyberduck.io" class="external-link">Cyberduck</a> application
is a free and intuitive GUI SFTP client. On Windows systems, <a href="https://winscp.net/eng/index.php" class="external-link">WinSCP</a> is another popular
choice.</p>
<p>The below screenshots show an example of connecting to
<code>csphbiostats.ucdenver.pvt</code> using Cyberduck on Mac.</p>
<p>First, open Cyberduck and click the ‘Open Connection’ button on the
top bar.</p>
<p><img src="figures/CIDA_BIOS_Cluster/cyberduck_1.png" width="80%" style="display: block; margin: auto;"></p>
<p>Next, ensure that the ‘SFTP’ option is selected in the dropdown, then
input your SSH credentials.</p>
<p><img src="figures/CIDA_BIOS_Cluster/cyberduck_2.png" width="80%" style="display: block; margin: auto;"></p>
<p>If successful, you should see a file browser interface showing your
home directory on <code>csphbiostats.ucdenver.pvt</code>.</p>
<p>You can use the interface to navigate and download and existing
files. You can also drag-and-drop files from your local machine to
upload them to the cluster.</p>
<p><img src="figures/CIDA_BIOS_Cluster/cyberduck_3.png" width="80%" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="networked-storage">Networked Storage<a class="anchor" aria-label="anchor" href="#networked-storage"></a>
</h3>
<p>The CSPH Biostats cluster uses a shared filesystem for many important
directories, including <code>/home</code> and
<code>/biostats_share</code>. This means that any files (scripts, data,
etc) you upload to one of these directories on
<code>csphbiostats.ucdenver.pvt</code> will be accessible from any node
in the cluster.</p>
<p>Similarly, any output files generated from a job running on a compute
node will also be accessible from
<code>csphbiostats.ucdenver.pvt</code>, making it easy to download the
results of a job.</p>
</div>
<div class="section level3">
<h3 id="other-slurm-resources">Other SLURM Resources<a class="anchor" aria-label="anchor" href="#other-slurm-resources"></a>
</h3>
<p>The SLURM system has an excellent <a href="https://slurm.schedmd.com/documentation.html" class="external-link">website</a>, with
documentation for each command. I recommend reading the documentation
for at least the <a href="https://slurm.schedmd.com/sbatch.html" class="external-link">sbatch</a> command, as it
contains information about many configuration options not listed in this
document.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by CIDA Research Tools Committee.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
